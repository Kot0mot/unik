Анализ алгоритма: Сортировка выбором (Selection Sort)

**Определение:**
Сортировка выбором — это алгоритм, разделяющий массив на две области: отсортированную и неотсортированную. На каждой итерации он отыскивает наименьший элемент в неотсортированной области и обменивает его с первым элементом этой области.

**Анализ:**
Алгоритм находит минимальный элемент в неотсортированной части и меняет его местами с первым элементом этой части.
Внешний цикл for выполняется (n-1) раз.
Внутренний цикл for в наихудшем случае выполняется (n-1), затем (n-2), ... раз за каждый проход внешнего цикла.
Суммарное количество сравнений приблизительно равно n*(n-1)/2.
**Временная сложность:** O(n²)
**Почему O(n²):** Два вложенных цикла, где каждый в среднем или худшем случае зависит от n. Внутренний цикл может выполняться до n раз для каждой из n итераций внешнего цикла, что дает квадратичную зависимость.

Анализ алгоритма: Сортировка обменом (пузырьком) (Bubble Sort)

**Определение:**
Сортировка обменом (или пузырьковая сортировка) — это простой алгоритм, который многократно проходит по массиву, сравнивая соседние элементы и меняя их местами, если они расположены в неправильном порядке.

**Анализ:**
Алгоритм проходит по массиву, сравнивая соседние элементы и обменивая их, если левый больше правого. Это обеспечивает "всплывание" наибольшего элемента в конец.
Внешний цикл for выполняется (n-1) раз.
Внутренний цикл for в наихудшем случае (когда массив отсортирован в обратном порядке) выполняется (n-1), затем (n-2), ... раз.
Оптимизация с флагом swapped дает возможность досрочно выйти из цикла, если массив уже отсортирован.
**Временная сложность:**
**Наихудший случай:** O(n²) — массив отсортирован в обратном порядке.
**Наилучший случай:** O(n) — массив уже отсортирован, срабатывает оптимизация.
**Средний случай:** O(n²)
**Почему O(n²):** В худшем случае, аналогично сортировке выбором, требует около n*(n-1)/2 сравнений и потенциальных обменов.

Анализ алгоритма: Сортировка вставками (Insertion Sort)

**Определение:**
Сортировка вставками — это алгоритм сортировки, в котором элементы входной последовательности просматриваются по одному, и каждый новый поступивший элемент размещается в подходящую позицию среди ранее упорядоченных элементов.

**Анализ:**
Алгоритм формирует отсортированную часть списка, начиная с первого элемента. Каждый новый элемент вставляется в корректную позицию среди уже отсортированных.
Внешний цикл for проходит по (n-1) элементам.
Внутренний цикл while в наихудшем случае (массив отсортирован в обратном порядке) может выполнить до i итераций на i-ой итерации внешнего цикла.
**Временная сложность:**
**Наихудший случай:** O(n²) — массив отсортирован в обратном порядке. Каждый элемент может потребовать i сдвигов.
**Наилучший случай:** O(n) — массив уже отсортирован. Внутренний цикл while не выполняется.
**Средний случай:** O(n²)
**Почему O(n²):** В худшем случае общее количество сдвигов и сравнений составляет 1 + 2 + 3 + ... + (n-1) = n*(n-1)/2.

Анализ алгоритма: Сортировка слиянием (Merge Sort)

**Определение:**
Сортировка слиянием — алгоритм сортировки, который упорядочивает списки (или другие структуры данных с последовательным доступом, например — потоки) в определенном порядке.

**Анализ:**
Алгоритм рекурсивно делит массив пополам до тех пор, пока не останутся подмассивы размером 1.
Затем он сливает эти подмассивы, формируя большие отсортированные подмассивы.
Это осуществляется с помощью функции merge, которая объединяет два уже отсортированных подмассива.
**Временная сложность:** O(n log n)
**Почему O(n log n):**
**Глубина рекурсии:** Массив делится пополам на каждом уровне рекурсии. Количество уровней (глубина дерева рекурсии) составляет log n.
**Работа на уровне:** На каждом уровне рекурсии мы сливаем n элементов (все элементы массива). Функция merge для всего массива на одном уровне выполняет O(n) операций.
**Общая сложность:** log n уровней * n элементов на уровне = O(n log n).

Анализ алгоритма: Сортировка Шелла (Shell Sort)

**Определение:**
Сортировка Шелла — это алгоритм сортировки, представляющий собой усовершенствованный вариант сортировки вставками. Идея метода Шелла заключается в сравнении элементов, стоящих не только рядом, но и на определенном расстоянии друг от друга.

**Анализ:**
Это модификация сортировки вставками. Она сначала сортирует элементы, находящиеся на определенном расстоянии (gap), затем уменьшает gap и повторяет процесс.
Выбор последовательности gap (например, n/2, n/4, ..., 1) влияет на производительность.
**Временная сложность:**
Зависит от выбранной последовательности gaps. Для последовательности, используемой в коде (n/2^k), сложность составляет O(n^(3/2)) или O(n log² n) в среднем случае, но может быть хуже.
В наихудшем случае (для некоторых последовательностей) может быть O(n²).
Для последовательности Кнута (gap = 3h + 1) сложность составляет O(n^(3/2)).
В общем, точная сложность часто выражается как O(n^p), где 1 < p <= 2.
**Почему O(n^p):** Алгоритм использует вложенные циклы, но внутренний цикл (по j) не всегда проходит n раз, как в пузырьке. Количество итераций зависит от gap. В среднем случае количество итераций внутреннего цикла увеличивается медленнее, чем n, приводя к сложности между O(n) и O(n^2).

Анализ алгоритма: Быстрая сортировка (Quick Sort)

**Определение:**
Быстрая сортировка — это эффективный алгоритм сортировки, использующий принцип «разделяй и властвуй».

**Анализ:**
Выбирается опорный элемент. Массив перераспределяется так, что элементы, меньшие или равные опорному, оказываются слева от него, а большие — справа.
Затем рекурсивно сортируются левая и правая части.
Выбор опорного элемента критически важен для производительности.
**Временная сложность:**
**Средний случай:** O(n log n) — если опорный элемент делит массив приблизительно пополам на каждом шаге.
**Наихудший случай:** O(n²) — если опорный элемент всегда является минимальным или максимальным (например, массив уже отсортирован, и опорный всегда последний). В этом случае дерево рекурсии имеет глубину n, а на каждом уровне выполняется n сравнений.
**Наилучший случай:** O(n log n) — если опорный всегда делит массив ровно пополам.
**Почему O(n log n) или O(n²):**
**Средний/Лучший:** Глубина рекурсии log n, на каждом уровне n сравнений (в partition). n * log n.
**Худший:** Глубина рекурсии n, на каждом уровне до n, n-1, n-2, ... сравнений. n + (n-1) + ... + 1 = n(n+1)/2 ≈ O(n²).

Анализ алгоритма: Пирамидальная сортировка (Heap Sort)

**Определение:**
Пирамидальная сортировка — это алгоритм сортировки сравнением, использующий структуру данных двоичная куча.

**Анализ:**
Сначала строится max-heap (бинарное дерево, где родитель >= детей).
Затем максимальный элемент (корень) извлекается и помещается в конец массива. Куча уменьшается, и свойство heap восстанавливается для оставшейся части.
**Временная сложность:** O(n log n)
**Почему O(n log n):**
**Построение кучи:** build_max_heap выполняет heapify для n/2 узлов. Каждый вызов heapify может иметь глубину log n. В сумме это O(n) (доказывается математически, так как большинство узлов находятся ближе к листьям).
**Сортировка:** Цикл for выполняется (n-1) раз. Внутри него вызывается heapify, который работает за O(log n) (глубина дерева). Итого n * O(log n) = O(n log n).
**Общая сложность:** O(n) (построение) + O(n log n) (сортировка) = O(n log n).

Анализ алгоритма: Последовательный (линейный) поиск (Linear Search)

**Определение:**
Последовательный (линейный) поиск — это простой алгоритм, который поочередно проверяет каждый элемент в наборе данных, пока не будет найден искомый элемент или не будет пройден весь список.

**Анализ:**
Алгоритм последовательно просматривает элементы массива, сравнивая их с искомым значением.
**Временная сложность:**
**Наихудший случай:** O(n) — элемент находится в конце массива или отсутствует.
**Наилучший случай:** O(1) — элемент находится в начале массива.
**Средний случай:** O(n/2) ≈ O(n)
**Почему O(n):** В худшем случае необходимо проверить все n элементов.

Анализ алгоритма: Бинарный поиск (Binary Search)

**Определение:**
Бинарный поиск — это алгоритм для поиска элемента в отсортированном массиве.

**Анализ:**
Алгоритм работает только с отсортированным массивом.
На каждом шаге область поиска уменьшается вдвое за счет сравнения с элементом в середине.
**Временная сложность:** O(log n)
**Почему O(log n):** На каждом шаге размер области поиска сокращается примерно вдвое. Количество шагов, необходимых для уменьшения n до 1, равно log₂ n.

Анализ алгоритма: Интерполирующий поиск (Interpolation Search)

**Определение:**
Интерполирующий поиск (интерполяционный поиск) — это алгоритм поиска значения в упорядоченном массиве чисел, который работает быстрее бинарного поиска при равномерном распределении данных.

**Анализ:**
Похож на бинарный поиск, но вместо деления пополам, предполагает позицию элемента на основе его значения и значений на границах, предполагая равномерное распределение.
**Временная сложность:**
**Средний случай (равномерное распределение):** O(log log n)
**Наихудший случай (неравномерное распределение):** O(n)
**Почему O(log log n) или O(n):**
**Средний:** При равномерном распределении, на каждом шаге размер области поиска уменьшается быстрее, чем в бинарном поиске. Количество шагов приблизительно равно log log n.
**Худший:** Если данные распределены неравномерно (например, большинство элементов сосредоточено в начале), pos может вычисляться близко к lo, и алгоритм может деградировать до линейного сканирования, проверяя каждый элемент по одному.

Анализ алгоритма: Поиск по Фибоначчи (Fibonacci Search)

**Определение:**
Поиск методом Фибоначчи — это итеративный алгоритм для поиска экстремума (минимума или максимума) унимодальной функции на заданном интервале, а также метод поиска нужного значения в отсортированном массиве.

**Анализ:**
Использует числа Фибоначчи для определения точек разбиения массива, аналогично бинарному поиску (деление на части), но с разными пропорциями.
**Временная сложность:** O(log n)
**Почему O(log n):** Количество чисел Фибоначчи до n примерно равно log n. Каждая итерация цикла while уменьшает размер области поиска, используя меньшие числа Фибоначчи, что приводит к O(log n) итераций.
